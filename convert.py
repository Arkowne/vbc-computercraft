#!/usr/bin/env python3
import os
import subprocess
import cv2
from PIL import Image
import nfp
import argparse
import random
import string
from blt import image_to_blt

def process_frame(frame, density):
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    h, w = rgb.shape[:2]
    ratio = w / h
    new_w = int(density * ratio)
    new_h = density
    resized = cv2.resize(rgb, (new_w, new_h), interpolation=cv2.INTER_AREA)
    pil_img = Image.fromarray(resized)
    return pil_img, resized.shape[1], resized.shape[0]

def generate_id(length=10):
    return ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))

def extract_audio_to_dfpwm(input_path, output_path):
    cmd = [
        'ffmpeg', '-y', '-i', input_path,
        '-vn', '-ac', '1', '-ar', '48000', '-c:a', 'dfpwm',
        output_path
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-i', '--input', required=True, help="Fichier vid√©o en entr√©e")
    parser.add_argument('-d', '--density', type=int, default=60, help="Densit√© NFP par frame")
    parser.add_argument('-f', '--fps', type=int, default=7, help="Images par seconde cible")
    args = parser.parse_args()

    video_id = generate_id()
    output_dir = os.path.join("videos", video_id)
    os.makedirs(output_dir, exist_ok=True)

    # üéµ Extraction audio
    out_audio = os.path.join(output_dir, 'audio.dfpwm')
    print(f"üîä Extraction audio vers {out_audio}")
    extract_audio_to_dfpwm(args.input, out_audio)

    # üéûÔ∏è Ouverture vid√©o
    cap = cv2.VideoCapture(args.input)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    source_fps = cap.get(cv2.CAP_PROP_FPS) or args.fps
    skip_ratio = int(round(source_fps / args.fps)) if args.fps < source_fps else 1
    print(f"üé• Source FPS: {source_fps:.2f}, Target FPS: {args.fps}, Skip ratio: {skip_ratio}")

    # üì∏ G√©n√©ration preview.jpg √† partir d'une frame al√©atoire
    rand_index = random.randint(0, max(0, total_frames - 1))
    cap.set(cv2.CAP_PROP_POS_FRAMES, rand_index)
    ret, frame = cap.read()
    if ret:
        pil_img, _, _ = process_frame(frame, args.density)
        preview_path = os.path.join(output_dir, "preview.jpg")
        pil_img.save(preview_path)
        print(f"üñºÔ∏è Image de pr√©visualisation enregistr√©e : {preview_path}")
    else:
        print("‚ùå Impossible de capturer une frame pour la preview.")

    # üîÅ Recommencer depuis le d√©but pour le vrai traitement
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    idx = 0
    frame_num = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if frame_num % skip_ratio == 0:
            temp_path = os.path.join(output_dir, f"_temp_{idx:05d}.png")
            cv2.imwrite(temp_path, frame)

            pil_img, resized_width, resized_height = process_frame(frame, args.density)
            blt_path = os.path.join(output_dir, f"frame_{idx:05d}.blt")
            image_to_blt(temp_path, blt_path, width=resized_width, height=resized_height)
            os.remove(temp_path)

            idx += 1
        frame_num += 1
    cap.release()

    # üìù Metadata
    meta = os.path.join(output_dir, 'metadata.txt')
    with open(meta, 'w') as m:
        m.write(f"fps={args.fps}\nframes={idx}\n")

    print(f"\n‚úÖ G√©n√©ration termin√©e !")
    print(f"üìÇ ID: {video_id}")
    print(f"üìÅ Dossier: {output_dir}")
    print(f"üñºÔ∏è {idx} frames | üéµ audio.dfpwm | üìù metadata.txt | üñºÔ∏è preview.jpg")

if __name__ == '__main__':
    main()
